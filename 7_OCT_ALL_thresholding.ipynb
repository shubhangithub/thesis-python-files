{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# file 1"
      ],
      "metadata": {
        "id": "-3fvJU5Q28q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Otsu Thresholds\n",
        "otsu_thresholds = {\n",
        "    'CD66b': 11.399895365332032,\n",
        "    'CD56': 3.4436964739765625,\n",
        "    'CD4': 4.638822374882812,\n",
        "    'CTLA4': 1.7203896906113283,\n",
        "    'CD8': 2.993261530101562,\n",
        "    'CD20': 1.8819881087285157\n",
        "}\n",
        "\n",
        "# IsoData Thresholds\n",
        "isodata_thresholds = {\n",
        "    'CD66b': 11.508348076880885,\n",
        "    'CD56': 3.468594647486471,\n",
        "    'CD4': 4.659877346459998,\n",
        "    'CTLA4': 1.7343134856874514,\n",
        "    'CD8': 3.0127165920619516,\n",
        "    'CD20': 1.885931165886635\n",
        "}\n",
        "\n",
        "# GMM Thresholds\n",
        "gmm_thresholds = {\n",
        "    'CD66b': 9.627310739032016,\n",
        "    'CD56': 7.673191841326574,\n",
        "    'CD4': 7.454448342344508,\n",
        "    'CTLA4': 1.6143088896363227,\n",
        "    'CD8': 5.6576234619684165,\n",
        "    'CD20': 1.414940867048797\n",
        "}\n",
        "\n",
        "# Minimum Cross-Entropy Thresholds\n",
        "cross_entropy_thresholds = {\n",
        "    'CD66b': 0.013985693,\n",
        "    'CD56': 3.255864025,\n",
        "    'CD4': 2.382756981,\n",
        "    'CTLA4': 1.889522099,\n",
        "    'CD8': 2.7746521,\n",
        "    'CD20': 1.802490234\n",
        "}\n",
        "\n",
        "# Load the previous output file as the new input file\n",
        "cells = pd.read_csv('/content/umap_filtered_002_TU2_Immune_2_thresholded_encoded.csv')\n",
        "\n",
        "# Predefined one-hot mapping (updated for all previous combinations)\n",
        "one_hot_mapping = {\n",
        "    'CD20': 1,\n",
        "    'CD66b': 2,\n",
        "    'CD8, CD20': 3,\n",
        "    'CTLA4': 4,\n",
        "    'CD4': 5,\n",
        "    'CD4, CTLA4': 6,\n",
        "    'CD8': 7,\n",
        "    'CD56': 8,\n",
        "    'CD4, CD8': 9,\n",
        "    'CD56, CD4': 10,\n",
        "    'CTLA4, CD8': 11,\n",
        "    'CD4, CTLA4, CD8': 12,\n",
        "    'CD4, CD20': 13,\n",
        "    'CD56, CD4, CTLA4, CD8': 14,\n",
        "    'CD20, CD8, CTLA4': 15,\n",
        "    'CD20, CD56, CD8, CTLA4': 16,\n",
        "    'CD20, CD8': 17,\n",
        "    'CD66b, CD8': 18,\n",
        "    'CD20, CD66b': 19,\n",
        "    'CD20, CTLA4': 20,\n",
        "    'CD20, CD66b, CD8': 21,\n",
        "    'CD56, CD8, CTLA4': 22,\n",
        "    'CD20, CD56, CD8': 23,\n",
        "    'CD20, CD56, CTLA4': 24,\n",
        "    'CD20, CD56': 25,\n",
        "    'CD20, CD4, CD8': 26,\n",
        "    'CD8, CTLA4': 27,\n",
        "    'CD56, CTLA4': 28,\n",
        "    'CD4, CD56, CTLA4': 29,\n",
        "    'CD56, CD8': 30,\n",
        "    'CD20, CD56, CD66b, CD8': 31,\n",
        "    'CD20, CD4, CTLA4': 32,\n",
        "    'CD20, CD4, CD56, CD8, CTLA4': 33,\n",
        "    'CD20, CD56, CD66b, CD8, CTLA4': 34,\n",
        "    'CD20, CD56, CD66b, CTLA4': 35,\n",
        "    'CD56, CD66b': 36,\n",
        "    'CD4, CD56, CD8': 37,\n",
        "    'CD20, CD4, CD8, CTLA4': 38,\n",
        "    'CD20, CD4': 39,\n",
        "    'CD4, CD8, CTLA4': 40,\n",
        "    'CD4, CD56': 41,\n",
        "    'CD20, CD4, CD56, CTLA4': 42,\n",
        "    'CD56, CD66b, CD8': 43,\n",
        "    'CD20, CD4, CD56': 44,\n",
        "    'CD20, CD66b, CTLA4': 45,\n",
        "    'CD20, CD56, CD66b': 46,\n",
        "    'CD4, CD56, CD8, CTLA4': 47,\n",
        "    'CD20, CD4, CD56, CD8': 48,\n",
        "    'CD20, CD4, CD66b, CD8, CTLA4': 49,\n",
        "    'CD20, CD4, CD56, CD66b, CD8, CTLA4': 50,\n",
        "    'CD20, CD4, CD66b, CD8': 51,\n",
        "    'CD20, CD66b, CD8, CTLA4': 52,\n",
        "    'CD20, CD4, CD66b': 53,\n",
        "    'CD20, CD4, CD56, CD66b, CD8': 54,\n",
        "    'CD4, CD66b': 55,\n",
        "    'CD4, CD56, CD66b, CD8': 56,\n",
        "    'CD4, CD66b, CTLA4': 57,\n",
        "    'CD4, CD66b, CD8': 58,\n",
        "    'CD20, CD4, CD66b, CTLA4': 59,\n",
        "    'CD4, CD56, CD66b': 60,\n",
        "    'CD20, CD4, CD56, CD66b, CTLA4': 61,\n",
        "    'CD66b, CD8, CTLA4': 62,\n",
        "    'CD4, CD56, CD66b, CTLA4': 63,\n",
        "    'CD20, CD4, CD56, CD66b': 64,\n",
        "    'CD4, CD66b, CD8, CTLA4': 65,\n",
        "    'CD56, CD66b, CTLA4': 66,\n",
        "    'CD66b, CTLA4': 67,\n",
        "    'CD4, CD56, CD66b, CD8, CTLA4': 68,\n",
        "    'CD56, CD66b, CD8, CTLA4': 69\n",
        "}\n",
        "\n",
        "# Initialize cluster ID for any new combinations (if needed)\n",
        "new_cluster_id = max(one_hot_mapping.values()) + 1\n",
        "\n",
        "# Track any new combinations not in the predefined one-hot mapping\n",
        "new_combinations = {}\n",
        "\n",
        "# Function to get a sorted list of expressed markers based on thresholds\n",
        "def get_expressed_markers(row, thresholds):\n",
        "    expressed = [marker for marker in thresholds.keys() if row[marker] > thresholds[marker]]\n",
        "    return expressed\n",
        "\n",
        "# Function to apply the one-hot encoding based on the predefined mapping or assign a new cluster ID\n",
        "def one_hot_encode(expressed):\n",
        "    if not expressed:\n",
        "        return 0\n",
        "    expressed_key = ', '.join(sorted(expressed))\n",
        "    if expressed_key in one_hot_mapping:\n",
        "        return one_hot_mapping[expressed_key]\n",
        "    else:\n",
        "        global new_cluster_id\n",
        "        new_combinations[expressed_key] = new_cluster_id\n",
        "        print(f\"New combination found: {expressed_key}. Assigning new cluster ID: {new_cluster_id}\")\n",
        "        new_cluster_id += 1\n",
        "        return new_combinations[expressed_key]\n",
        "\n",
        "# Process cells for a given thresholding method\n",
        "def process_cells(cells, thresholds, method_name):\n",
        "    expressed_markers_col = f'{method_name}_expressed_markers'\n",
        "    cluster_col = f'{method_name}_cluster'\n",
        "\n",
        "    # Initialize the new columns\n",
        "    cells[expressed_markers_col] = ''\n",
        "    cells[cluster_col] = 0\n",
        "\n",
        "    for index, row in cells.iterrows():\n",
        "        expressed = get_expressed_markers(row, thresholds)\n",
        "        cells.at[index, expressed_markers_col] = ', '.join(expressed)\n",
        "        cells.at[index, cluster_col] = one_hot_encode(expressed)\n",
        "\n",
        "    # Save the modified DataFrame\n",
        "    output_path = f'/content/output/002_TU2_Immune_2_NEW_thresholded_encoded.csv'\n",
        "    cells.to_csv(output_path, index=False)\n",
        "    print(f\"\\nModified CSV saved as {output_path}\")\n",
        "\n",
        "# Process for each method\n",
        "process_cells(cells, otsu_thresholds, 'otsu')\n",
        "process_cells(cells, isodata_thresholds, 'isodata')\n",
        "process_cells(cells, gmm_thresholds, 'gmm')\n",
        "process_cells(cells, cross_entropy_thresholds, 'cross_entropy')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uLQyefy2fWY",
        "outputId": "7edcfa4b-3d20-491b-884b-4ccff7d6c491"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modified CSV saved as /content/output/002_TU2_Immune_2_NEW_thresholded_encoded.csv\n",
            "\n",
            "Modified CSV saved as /content/output/002_TU2_Immune_2_NEW_thresholded_encoded.csv\n",
            "\n",
            "Modified CSV saved as /content/output/002_TU2_Immune_2_NEW_thresholded_encoded.csv\n",
            "\n",
            "Modified CSV saved as /content/output/002_TU2_Immune_2_NEW_thresholded_encoded.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# file 2"
      ],
      "metadata": {
        "id": "lB4mBwNR3D8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Otsu Thresholds for File 2\n",
        "otsu_thresholds_2 = {\n",
        "    'CD66b': 11.526461259472656,\n",
        "    'CD56': 9.262819014326173,\n",
        "    'CD4': 2.8504523409902345,\n",
        "    'CTLA4': 1.933787454142578,\n",
        "    'CD8': 6.184541287667969,\n",
        "    'CD20': 1.1763268841464845\n",
        "}\n",
        "\n",
        "# IsoData Thresholds for File 2\n",
        "isodata_thresholds_2 = {\n",
        "    'CD66b': 16.296615047849976,\n",
        "    'CD56': 9.377226506620305,\n",
        "    'CD4': 2.8735494212507433,\n",
        "    'CTLA4': 1.9447332524313428,\n",
        "    'CD8': 6.220227254473769,\n",
        "    'CD20': 1.1617175959772181\n",
        "}\n",
        "\n",
        "# GMM Thresholds for File 2\n",
        "gmm_thresholds_2 = {\n",
        "    'CD66b': 52.387916334350905,\n",
        "    'CD56': 18.918180984619028,\n",
        "    'CD4': 4.931560153011872,\n",
        "    'CTLA4': 3.1347858918554303,\n",
        "    'CD8': 7.472530599598466,\n",
        "    'CD20': 5.566258443848004\n",
        "}\n",
        "\n",
        "# Minimum Cross-Entropy Thresholds for File 2\n",
        "cross_entropy_thresholds_2 = {\n",
        "    'CD66b': 0.001524847,\n",
        "    'CD56': 4.812113444,\n",
        "    'CD4': 1.469428628,\n",
        "    'CTLA4': 1.758620447,\n",
        "    'CD8': 3.468239724,\n",
        "    'CD20': 0.002003243\n",
        "}\n",
        "\n",
        "# Load the second file\n",
        "cells_2 = pd.read_csv('/content/umap_filtered_CC_OC_585_TU1_Immune_1_thresholded_encoded.csv')\n",
        "\n",
        "# Initialize cluster ID for new combinations\n",
        "new_cluster_id = max(one_hot_mapping.values()) + 1\n",
        "\n",
        "# Track any new combinations not in the predefined one-hot mapping\n",
        "new_combinations = {}\n",
        "\n",
        "# Function to get a sorted list of expressed markers based on thresholds\n",
        "def get_expressed_markers(row, thresholds):\n",
        "    expressed = [marker for marker in thresholds.keys() if row[marker] > thresholds[marker]]\n",
        "    return expressed\n",
        "\n",
        "# Function to apply the one-hot encoding based on the predefined mapping or assign a new cluster ID\n",
        "def one_hot_encode(expressed):\n",
        "    if not expressed:\n",
        "        return 0\n",
        "    expressed_key = ', '.join(sorted(expressed))\n",
        "    if expressed_key in one_hot_mapping:\n",
        "        return one_hot_mapping[expressed_key]\n",
        "    else:\n",
        "        global new_cluster_id\n",
        "        new_combinations[expressed_key] = new_cluster_id\n",
        "        print(f\"New combination found: {expressed_key}. Assigning new cluster ID: {new_cluster_id}\")\n",
        "        new_cluster_id += 1\n",
        "        return new_combinations[expressed_key]\n",
        "\n",
        "# Process cells for a given thresholding method\n",
        "def process_cells(cells, thresholds, method_name):\n",
        "    expressed_markers_col = f'{method_name}_expressed_markers'\n",
        "    cluster_col = f'{method_name}_cluster'\n",
        "\n",
        "    # Initialize the new columns\n",
        "    cells[expressed_markers_col] = ''\n",
        "    cells[cluster_col] = 0\n",
        "\n",
        "    for index, row in cells.iterrows():\n",
        "        expressed = get_expressed_markers(row, thresholds)\n",
        "        cells.at[index, expressed_markers_col] = ', '.join(expressed)\n",
        "        cells.at[index, cluster_col] = one_hot_encode(expressed)\n",
        "\n",
        "    # Save the modified DataFrame\n",
        "    output_path = f'/content/output/CC_OC_585_TU1_Immune_1_NEW_thresholded_encoded.csv'\n",
        "    cells.to_csv(output_path, index=False)\n",
        "    print(f\"\\nModified CSV saved as {output_path}\")\n",
        "\n",
        "# Process for each method on file 2\n",
        "process_cells(cells_2, otsu_thresholds_2, 'otsu')\n",
        "process_cells(cells_2, isodata_thresholds_2, 'isodata')\n",
        "process_cells(cells_2, gmm_thresholds_2, 'gmm')\n",
        "process_cells(cells_2, cross_entropy_thresholds_2, 'cross_entropy')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mkobBqx3DaA",
        "outputId": "7efa00b6-5506-4721-caca-7c29ae5b594f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modified CSV saved as /content/output/CC_OC_585_TU1_Immune_1_NEW_thresholded_encoded.csv\n",
            "\n",
            "Modified CSV saved as /content/output/CC_OC_585_TU1_Immune_1_NEW_thresholded_encoded.csv\n",
            "\n",
            "Modified CSV saved as /content/output/CC_OC_585_TU1_Immune_1_NEW_thresholded_encoded.csv\n",
            "\n",
            "Modified CSV saved as /content/output/CC_OC_585_TU1_Immune_1_NEW_thresholded_encoded.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Below is the methods"
      ],
      "metadata": {
        "id": "-zLpwuSj2zQD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# otsu"
      ],
      "metadata": {
        "id": "iAXLiH5qPrQ5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2waBP8tMPnGU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage.filters import threshold_otsu\n",
        "\n",
        "def otsu_thresholding(df, marker_columns):\n",
        "    \"\"\"\n",
        "    Apply Otsu's thresholding method to each marker column in the dataset using skimage library.\n",
        "\n",
        "    Args:\n",
        "    df (pd.DataFrame): DataFrame containing marker intensity values.\n",
        "    marker_columns (list): List of marker columns to compute the thresholds for.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with the optimal thresholds for each marker.\n",
        "    \"\"\"\n",
        "    thresholds = {}\n",
        "\n",
        "    for marker in marker_columns:\n",
        "        # Get the intensity values for the current marker\n",
        "        intensities = df[marker].values\n",
        "\n",
        "        # Use skimage's Otsu method to find the optimal threshold\n",
        "        optimal_threshold = threshold_otsu(intensities)\n",
        "\n",
        "        # Store the optimal threshold for the current marker\n",
        "        thresholds[marker] = optimal_threshold\n",
        "\n",
        "    return thresholds\n",
        "\n",
        "# Example usage:\n",
        "# df = pd.read_csv(\"your_data.csv\")\n",
        "# marker_columns = ['CD66b', 'CD56', 'CD4', 'CTLA4', 'CD8', 'CD20']\n",
        "# thresholds = otsu_thresholding(df, marker_columns)\n",
        "# print(thresholds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IsoData"
      ],
      "metadata": {
        "id": "CU5pDNgyPtDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def isodata_thresholding(df, marker_columns, epsilon=1e-5, max_iter=1000):\n",
        "    \"\"\"\n",
        "    Apply the IsoData thresholding method to each marker column in the dataset.\n",
        "\n",
        "    Args:\n",
        "    df (pd.DataFrame): DataFrame containing marker intensity values.\n",
        "    marker_columns (list): List of marker columns to compute the thresholds for.\n",
        "    epsilon (float): Convergence tolerance for the threshold update.\n",
        "    max_iter (int): Maximum number of iterations allowed.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with the optimal thresholds for each marker.\n",
        "    \"\"\"\n",
        "    thresholds = {}\n",
        "\n",
        "    for marker in marker_columns:\n",
        "        # Get the intensity values for the current marker\n",
        "        intensities = df[marker].values\n",
        "\n",
        "        # Initialize the threshold as the mean of the intensities\n",
        "        threshold = np.mean(intensities)\n",
        "\n",
        "        for _ in range(max_iter):\n",
        "            # Partition the cells into two classes based on the current threshold\n",
        "            C0 = intensities[intensities <= threshold]\n",
        "            C1 = intensities[intensities > threshold]\n",
        "\n",
        "            if len(C0) == 0 or len(C1) == 0:\n",
        "                break\n",
        "\n",
        "            # Compute the means of the two classes\n",
        "            mu_0 = np.mean(C0)\n",
        "            mu_1 = np.mean(C1)\n",
        "\n",
        "            # Update the threshold as the average of the two class means\n",
        "            new_threshold = (mu_0 + mu_1) / 2\n",
        "\n",
        "            # Check for convergence\n",
        "            if np.abs(new_threshold - threshold) < epsilon:\n",
        "                break\n",
        "\n",
        "            # Update the threshold for the next iteration\n",
        "            threshold = new_threshold\n",
        "\n",
        "        # Store the final threshold for the current marker\n",
        "        thresholds[marker] = threshold\n",
        "\n",
        "    return thresholds\n",
        "\n",
        "# Example usage:\n",
        "# df = pd.read_csv(\"your_data.csv\")\n",
        "# marker_columns = ['CD66b', 'CD56', 'CD4', 'CTLA4', 'CD8', 'CD20']\n",
        "# thresholds_isodata = isodata_thresholding(df, marker_columns)\n",
        "# print(thresholds_isodata)\n"
      ],
      "metadata": {
        "id": "MysaepwoPvjd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Modified Version of GMM"
      ],
      "metadata": {
        "id": "6kL26vMbQOAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "import numpy as np\n",
        "\n",
        "def modified_gmm_thresholding(data_df, markers, max_components=10, random_state=42):\n",
        "    thresholds = {}\n",
        "\n",
        "    for marker in markers:\n",
        "        # Extract marker values\n",
        "        marker_values = data_df[[marker]].values\n",
        "\n",
        "        # Best GMM selection based on BIC\n",
        "        best_gmm = None\n",
        "        lowest_bic = np.inf\n",
        "        best_n_components = 2  # Start with 2 components by default\n",
        "\n",
        "        # Try different number of components (K)\n",
        "        for n_components in range(2, max_components + 1):\n",
        "            gmm = GaussianMixture(n_components=n_components, random_state=random_state)\n",
        "            gmm.fit(marker_values)\n",
        "            bic = gmm.bic(marker_values)\n",
        "\n",
        "            if bic < lowest_bic:\n",
        "                lowest_bic = bic\n",
        "                best_gmm = gmm\n",
        "                best_n_components = n_components\n",
        "\n",
        "        # Handle K = 2 case (simple thresholding)\n",
        "        if best_n_components == 2:\n",
        "            threshold = np.mean(best_gmm.means_)\n",
        "\n",
        "        # Handle K > 2 case (custom thresholding based on largest gap)\n",
        "        else:\n",
        "            means = np.sort(best_gmm.means_.flatten())\n",
        "            delta_means = np.diff(means)\n",
        "            k_boundary = np.argmax(delta_means)\n",
        "            threshold = (means[k_boundary] + means[k_boundary + 1]) / 2\n",
        "\n",
        "        # Store threshold and create binary column for above threshold\n",
        "        thresholds[marker] = threshold\n",
        "\n",
        "\n",
        "    return thresholds\n",
        "\n",
        "# Example usage:\n",
        "# data_df = pd.read_csv(\"your_data.csv\")\n",
        "# markers = ['CD66b', 'CD56', 'CD4', 'CTLA4', 'CD8', 'CD20']\n",
        "# updated_df, thresholds = apply_gmm_thresholding(data_df, markers)\n",
        "# print(\"GMM Thresholds:\", thresholds)\n"
      ],
      "metadata": {
        "id": "ONpzDlYvQVvD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# minimum cross-entropy"
      ],
      "metadata": {
        "id": "0uVJIWF8R1Am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import norm, lognorm, gamma, expon  # For fitting distributions\n",
        "\n",
        "# Ensure you have defined or imported the following functions:\n",
        "# - fit_distribution: to fit the distribution (normal, lognormal, gamma, exponential)\n",
        "# - cross_entropy: to calculate cross-entropy between distributions\n",
        "\n",
        "# Example fit_distribution function (you may need to adjust this to your actual implementation)\n",
        "def fit_distribution(data, dist_name='normal'):\n",
        "    if dist_name == 'normal':\n",
        "        return norm(loc=np.mean(data), scale=np.std(data))\n",
        "    elif dist_name == 'lognormal':\n",
        "        return lognorm(s=np.std(np.log(data)), scale=np.exp(np.mean(np.log(data))))\n",
        "    elif dist_name == 'gamma':\n",
        "        return gamma(a=np.mean(data), scale=np.std(data))\n",
        "    elif dist_name == 'exponential':\n",
        "        return expon(scale=np.mean(data))\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Example cross_entropy function (you may need to adjust based on your implementation)\n",
        "def cross_entropy(data, probabilities):\n",
        "    return -np.sum(np.log(probabilities + 1e-9))  # Add small value to avoid log(0) issues\n"
      ],
      "metadata": {
        "id": "oAfMqxAL1VYH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def min_cross_entropy_thresholding(data_df, marker_columns, candidate_thresholds, dist_name='normal'):\n",
        "    \"\"\"\n",
        "    Apply Minimum Cross-Entropy Thresholding for each marker in the DataFrame.\n",
        "\n",
        "    Args:\n",
        "    data_df: DataFrame containing the marker intensity values.\n",
        "    marker_columns: List of marker columns to apply the thresholding.\n",
        "    candidate_thresholds: Dictionary of candidate thresholds for each marker.\n",
        "    dist_name: Distribution to use ('normal', 'lognormal', 'gamma', 'exponential').\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with the optimal threshold for each marker.\n",
        "    \"\"\"\n",
        "    thresholds = {}\n",
        "\n",
        "    for marker in marker_columns:\n",
        "        data = data_df[marker].values\n",
        "        unique_thresholds = candidate_thresholds[marker]  # Now correctly referencing marker-specific thresholds\n",
        "\n",
        "        def objective(threshold):\n",
        "            non_expressing = data[data <= threshold]\n",
        "            expressing = data[data > threshold]\n",
        "\n",
        "            if len(non_expressing) == 0 or len(expressing) == 0:\n",
        "                return np.inf  # Avoid empty class case\n",
        "\n",
        "            dist_non_exp = fit_distribution(non_expressing, dist_name)\n",
        "            dist_exp = fit_distribution(expressing, dist_name)\n",
        "\n",
        "            if dist_non_exp is None or dist_exp is None:\n",
        "                return np.inf\n",
        "\n",
        "            # Compute cross-entropy\n",
        "            p0 = dist_non_exp.pdf(non_expressing)\n",
        "            p1 = dist_exp.pdf(expressing)\n",
        "\n",
        "            ce_non_exp = cross_entropy(non_expressing, p0)\n",
        "            ce_exp = cross_entropy(expressing, p1)\n",
        "\n",
        "            return ce_non_exp + ce_exp\n",
        "\n",
        "        # Use scipy's minimize to find the optimal threshold\n",
        "        result = minimize(objective, x0=[np.median(data)], bounds=[(min(data), max(data))])\n",
        "\n",
        "        # Store the best threshold\n",
        "        thresholds[marker] = result.x[0] if result.success else None\n",
        "\n",
        "    return thresholds\n"
      ],
      "metadata": {
        "id": "g0GrQh9QR3XT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# generate candiadate thresholds"
      ],
      "metadata": {
        "id": "d1_FJNmjB7NC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_candidate_thresholds(df, marker_columns):\n",
        "    \"\"\"\n",
        "    Generate candidate thresholds based on unique intensity values for each marker.\n",
        "\n",
        "    Args:\n",
        "    df (pd.DataFrame): DataFrame containing marker intensity values.\n",
        "    marker_columns (list): List of marker columns to compute the thresholds for.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with marker names as keys and their corresponding unique intensity thresholds as values.\n",
        "    \"\"\"\n",
        "    candidate_thresholds = {}\n",
        "\n",
        "    for marker in marker_columns:\n",
        "        # Get the unique intensity values for the current marker, sorted\n",
        "        unique_intensities = np.sort(df[marker].unique())\n",
        "        candidate_thresholds[marker] = unique_intensities\n",
        "\n",
        "    return candidate_thresholds\n",
        "\n",
        "# Example usage:\n",
        "# df = pd.read_csv(\"your_data.csv\")\n",
        "# marker_columns = ['CD66b', 'CD56', 'CD4', 'CTLA4', 'CD8', 'CD20']\n",
        "# candidate_thresholds = generate_candidate_thresholds(df, marker_columns)\n",
        "# print(candidate_thresholds)\n"
      ],
      "metadata": {
        "id": "y7sxzCmVB6mU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load and run data"
      ],
      "metadata": {
        "id": "tMJzAcvcS8W_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import pandas as pd\n",
        "\n",
        "# Load your data\n",
        "df = pd.read_csv(\"/content/umap_filtered_CC_OC_585_TU1_Immune_1_thresholded_encoded.csv\")\n",
        "\n",
        "marker_columns = ['CD66b', 'CD56', 'CD4', 'CTLA4', 'CD8', 'CD20']\n",
        "\n",
        "thresholds_otsu = otsu_thresholding(df, marker_columns)\n",
        "print(\"Otsu Thresholds:\", thresholds_otsu)\n",
        "\n",
        "\n",
        "thresholds_isodata = isodata_thresholding(df, marker_columns)\n",
        "print(\"IsoData Thresholds:\", thresholds_isodata)\n",
        "\n",
        "thresholds_gmm = modified_gmm_thresholding(df, marker_columns)\n",
        "print(\"GMM Thresholds:\", thresholds_gmm)\n",
        "\n",
        "candidate_thresholds = generate_candidate_thresholds(df, marker_columns)\n",
        "\n",
        "\n",
        "for marker in marker_columns:\n",
        "    thresholds_mce = min_cross_entropy_thresholding(df, [marker], candidate_thresholds)\n",
        "    print(f\"Minimum Cross-Entropy Threshold for {marker}: {thresholds_mce}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "UsUF2NCkS-Kb",
        "outputId": "3a9a2577-4033-4f3d-b9c6-41bbf54a50fb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/umap_filtered_CC_OC_585_TU1_Immune_1_NEW_thresholded_encoded.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e325ad89f509>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load your data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/umap_filtered_CC_OC_585_TU1_Immune_1_NEW_thresholded_encoded.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmarker_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'CD66b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CD56'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CD4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CTLA4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CD8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CD20'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/umap_filtered_CC_OC_585_TU1_Immune_1_NEW_thresholded_encoded.csv'"
          ]
        }
      ]
    }
  ]
}